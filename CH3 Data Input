# (3.1) Input from Text Files
# (3.1.1) Visual Inspection: check for things like is there a header/footer? Are there empy lines at the end of the file? Are there whitespaces before the first number or at the end of each line?

# (3.1.2) Reading ASCII-Data into Python

# simple text files ('data.txt')
# data.txt is something like this:
# 1, 1.3, 0.6
# 2, 2.1, 0.7
# 3, 4.8, 0.8
# 4, 3.3, 0.9
data = np.loadtxt('data.txt', delimiter = ',')
# or
df = pd.read_csv('data.txt', header=None)   # note you usually need to include this header part

# more complex text files
# data2.txt is something like this:
# patient_id, weight, value
# 1, 1.3, 0.6
# 2, 2.1, 0.7
# 3, 4.8, 0.8
# 4, 3.3, 0.9
# these are dummy files blah blah
# April 2020
# use skipfooter
df2 = pd.read_csv('data2.txt',
                  skipfooter=3, delimiter='[ ,]*')
                  
# Regex
df =pd.read_csv(inFile, sep='[ ;,]+')
# this reads in data from a file, seperated by a combo of commas, semicolons, or whitespaces
data=np.round(np.random.randin(100,7), 2)
df = pd.DataFrame(data, columns= ['Time',
                                  'PosX', 'PosY', 'PosZ', 'VelX', 'VelY', 'VelZ'])
vel = df.filter(regex='Vel*')
#extracts columns starting with 'Vel'

# MS Excel: two functions here, read_excel (Pandas) or ExcelFile (Class)
# read_excel: for reading one file with file-specific arguments (i.e. identical formats across each sheet)
# ExcelFile: for reading one file with sheet-specific arguments(i.e. different formats across sheets)

# ex1: reading a single sheet
# using ExcelFile class
xls = pd.ExcelFile('path_to_file.xls')
data = xls.parse('Sheet1', index_col=None, na_values=['NA'])

# using read_excel function
data = pd.read_excel('path_to_file.xls', 'Sheet1',
                     index_col = None, na_values = ['NA'])

# advanced script to directly import data from an Excel file which is stored in a zipped archive on the web

# import standard packages
import pandas as pd

# import additional packages
import io
import zipfile

def getDataDobson(url, inFile):
    '''extracts data from a zipped archive on the web'''
    
    #get the zip-archive
    GLM_archive = urlopen(url).read()
    
    #make the archive available as a byte-stream
    zipdata = io.BytesIO()
    zipdata.write(GLM_archive)
    
    #extract the file from the archive, as a pandas XLS-file
    myzipfile = zipfile.ZipFile(zipdata)
    xlsfile = myzipfile.open(inFile)
    
    #read the xls-file into Python, using Pandas, and return extracted data
    xls  = pd.ExcelFile(xlsfile)
    df = xls.parse('Sheet1', skiprows=2)
    
    return df

if __name__=='__main__':
    #select archive(on the web) and the file in the archive
    url = 'http://cdn.crcpress.com/downloads/C9500/GLM_data.zip'
    inFile = r'GLM_data/Table 2.8 Wasit loss.xls'
    
    df = getDataDobson(url, inFile)
    print(df)
    
    input('All done!')

